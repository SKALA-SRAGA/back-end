import logging
import os
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_teddynote.messages import stream_response
from app.dto.message_request import MessageRequest

OPENAI_API_KEY=os.getenv("OPENAI_API_KEY")

model = ChatOpenAI(
    model="gpt-4o-mini", 
    temperature=0.5, 
    openai_api_key=OPENAI_API_KEY, 
    streaming=True
)

templete='{text}ì„ {lang}ë¡œ ë²ˆì—­í•´ì£¼ì„¸ìš”. ë²ˆì—­ ëœ ë¬¸ì¥ë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”.'
prompt = PromptTemplate.from_template(templete)
output_parser = StrOutputParser()
chain = prompt | model | output_parser

async def get_streaming_message_from_openai(data: MessageRequest):

    print("ğŸ”‘ Loaded API Key:", OPENAI_API_KEY)

    try:
        # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
        response = chain.astream({
            "text": data.message,
            "lang": data.lang
        })

        async for token in response:
            content = f"data: {token}\n\n"
            logging.info(f"Yielding token: {content}")
            yield content
        yield "data: [DONE]\n\n"
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜
        yield f"[Error: {str(e)}]"